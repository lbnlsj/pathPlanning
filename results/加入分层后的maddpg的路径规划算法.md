
# 分层MADDPG路径规划算法伪代码

### 智能体分层结构

```markdown
class HierarchicalAgents:
    1. 领导者(Leaders):
        - 负责全局路径规划和决策
        - 具有更大的感知范围
        - 与其他领导者协调
        
    2. 跟随者(Followers):
        - 被分配给最近的领导者
        - 局部避障和跟随
        - 与邻近智能体协调
        
    3. 分配机制:
        - 基于距离分配跟随者到领导者
        - 动态更新分配关系
        - 平衡每个领导者的跟随者数量
```

### 层次化图神经网络

```markdown
class HierarchicalGNN:
    1. 领导者层网络:
        Input: 领导者状态、全局目标
        - 高层图注意力层1: state -> 128维
        - 高层图注意力层2: 128维 -> 64维
        - 策略层: 64维 -> 全局行动指令
        
    2. 跟随者层网络:
        Input: 跟随者状态、领导者指令
        - 底层图注意力层1: state -> 64维
        - 底层图注意力层2: 64维 -> 32维
        - 执行层: 32维 -> 局部行动
```

### 多层次路径规划

```markdown
class HierarchicalPathPlanning:
    1. 全局路径规划(领导者):
        a) 环境分析:
            - 构建全局代价地图
            - 识别关键路径点
            - 评估出口可达性
            
        b) 领导者协调:
            - 区域分配
            - 避免路径冲突
            - 动态调整计划
            
    2. 局部路径规划(跟随者):
        a) 跟随行为:
            - 保持与领导者的安全距离
            - 避免局部碰撞
            - 形成队列结构
            
        b) 局部优化:
            - 速度匹配
            - 间距调整
            - 避障机动
```

### 主算法流程

```markdown
初始化:
    1. 创建分层网络结构
    2. 初始化领导者和跟随者智能体
    3. 配置噪声生成器
    4. 构建经验回放缓存

训练过程:
    For each episode:
        重置环境和噪声
        初始分配跟随者给领导者
        
        For each step:
            1. 构建多层次交互图:
                a) 领导者层:
                    - 领导者间的交互图
                    - 全局环境信息
                    
                b) 跟随者层:
                    - 跟随者与邻近智能体的局部图
                    - 与指定领导者的连接
                
            2. 分层决策:
                a) 领导者决策:
                    - 使用领导者Actor生成全局指令
                    - 添加探索噪声
                    - 广播指令给跟随者
                    
                b) 跟随者决策:
                    - 接收领导者指令
                    - 结合局部观察生成动作
                    - 添加局部噪声
                
            3. 执行与学习:
                a) 执行动作:
                    - 同步执行所有智能体的动作
                    - 收集反馈和奖励
                    
                b) 经验存储:
                    - 分别存储领导者和跟随者的经验
                    - 记录层级关系
                    
                c) 网络更新:
                    1) 领导者网络更新:
                        - 更新领导者Actor和Critic
                        - 使用全局奖励信号
                        
                    2) 跟随者网络更新:
                        - 更新跟随者Actor和Critic
                        - 使用混合奖励信号
                        
            4. 动态调整:
                - 更新跟随者分配
                - 调整噪声参数
                - 优化通信结构
```

### 奖励设计

```markdown
1. 领导者奖励:
    - 群体疏散进度
    - 跟随者队形维持
    - 路径效率
    - 通信开销
    
2. 跟随者奖励:
    - 跟随性能
    - 碰撞避免
    - 局部任务完成
    - 协作表现
    
3. 群体奖励:
    - 整体疏散时间
    - 拥堵程度
    - 系统稳定性
```

### 关键创新点

1. **分层控制架构**:
   - 领导者负责全局规划和协调
   - 跟随者专注于局部执行和避障

2. **多层次图结构**:
   - 分离领导者和跟随者的交互网络
   - 自适应的层间通信机制

3. **混合噪声策略**:
   - 领导者使用策略级噪声促进全局探索
   - 跟随者使用执行级噪声优化局部行为

4. **层次化学习**:
   - 分离的价值评估和策略更新
   - 考虑层级间的依赖关系

